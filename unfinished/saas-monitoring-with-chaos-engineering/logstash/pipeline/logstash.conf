input {
  file {
    path => "/mnt/data/suricata/eve.json"
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/data/sincedb-eve"
    codec => json
  }
}

filter {
  # Map core Suricata fields to ECS
  mutate {
    rename => {
      "src_ip"    => "[source][ip]"
      "dest_ip"   => "[destination][ip]"
      "src_port"  => "[source][port]"
      "dest_port" => "[destination][port]"
      "proto"     => "[network][transport]"
      "app_proto" => "[network][protocol]"
    }
    add_field => {
      "[event][module]" => "suricata"
      "[observer][type]" => "ids"
    }
  }

  # Use Suricata's timestamp as @timestamp
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
    remove_field => ["timestamp"]
  }

  # Mark alerts
  if [event_type] == "alert" {
    mutate {
      add_field => {
        "[event][kind]"      => "alert"
        "[event][category]"  => "network"
        "[event][type]"      => "info"
        "[rule][name]"       => "%{[alert][signature]}"
        "[rule][id]"         => "%{[alert][signature_id]}"
        "[rule][severity]"   => "%{[alert][severity]}"
      }
    }
  } else {
    mutate { add_field => { "[event][category]" => "network" } }
  }
}

output {
  elasticsearch {
    hosts    => "http://elasticsearch:9200"
    user     => "logstash_internal"
    password => "${LOGSTASH_INTERNAL_PASSWORD}"

    # <-- Write to a data stream that Kibana's “All logs” picks up automatically
    data_stream => true
    data_stream_type => "logs"
    data_stream_dataset => "suricata.eve"
    data_stream_namespace => "default"
  }
}
